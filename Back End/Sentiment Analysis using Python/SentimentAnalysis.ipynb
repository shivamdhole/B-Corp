{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Source: https://www.youtube.com/watch?list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL&v=eObouMO2qSE\n",
    "Author: Shivam Dhole\n",
    "Student No: 741507\n",
    "\n",
    "Description:\n",
    "This code loads six classifiersusing pickle. These clsssifiers are pre trained and stored in text files.\n",
    "The code loades these trained classifiers and uses it to find sentiment of a given string.\n",
    "This code is run on tweets stored in CouchDB.\n",
    "The tweets are filtered using an attribute called 'python'.\n",
    "All the tweets who have this attribute false, sentiment analysis using NLTK is done on them.\n",
    "The second sentiment analysis is performed using Textblob.\n",
    "The same text goes through the Textblob function and returns polarity of the tweet.\n",
    "The sentiment value is calculated using both methods and the document is updated with it.\n",
    "'''\n",
    "\n",
    "import nltk\n",
    "import random\n",
    "import couchdb\n",
    "import datetime\n",
    "from textblob import TextBlob\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "\n",
    "\n",
    "documents_f = open(\"documents.pickle\", \"rb\")\n",
    "documents = pickle.load(documents_f)\n",
    "documents_f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "word_features5k_f = open(\"word_features5k.pickle\", \"rb\")\n",
    "word_features = pickle.load(word_features5k_f)\n",
    "word_features5k_f.close()\n",
    "\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "featuresets_f = open(\"word_features5k.pickle\", \"rb\")\n",
    "featuresets = pickle.load(featuresets_f)\n",
    "featuresets_f.close()\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "print(len(featuresets))\n",
    "\n",
    "testing_set = featuresets[10000:]\n",
    "training_set = featuresets[:10000]\n",
    "\n",
    "\n",
    "\n",
    "open_file = open(\"originalnaivebayes5k.pickle\", \"rb\")\n",
    "classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"MNB_classifier5k.pickle\", \"rb\")\n",
    "MNB_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "\n",
    "open_file = open(\"BernoulliNB_classifier5k.pickle\", \"rb\")\n",
    "BernoulliNB_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"LogisticRegression_classifier5k.pickle\", \"rb\")\n",
    "LogisticRegression_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"LinearSVC_classifier5k.pickle\", \"rb\")\n",
    "LinearSVC_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"SGDC_classifier5k.pickle\", \"rb\")\n",
    "SGDC_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "voted_classifier = VoteClassifier(\n",
    "                                  classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    return voted_classifier.classify(feats),voted_classifier.confidence(feats)\n",
    "\n",
    "# Getting document and performing analysis starts here\n",
    "couch = couchdb.Server('http://xxx.xxx.xxx.xxx:5984/')\n",
    "\n",
    "db = couch['newtweets']\n",
    "count = 0\n",
    "for docid in db.view('shivam/pythonfalse'):\n",
    "    i = docid['id']\n",
    "    doc = db.get(i)\n",
    "    text = doc[\"text\"]\n",
    "    testimonial = TextBlob(text)\n",
    "    s = sentiment(text)\n",
    "    pol = testimonial.polarity\n",
    "    sub = testimonial.subjectivity\n",
    "    doc[\"NLTKsentiment\"] = s[0]\n",
    "    doc[\"textblobpolarity\"] = pol\n",
    "    doc[\"textblobsubjectivity\"] = sub\n",
    "    doc[\"python\"] = True\n",
    "    doc = db.save(doc)\n",
    "    count = count+1\n",
    "    if count%10000 == 0: # To track progress of code\n",
    "        print(count,datetime.datetime.now())\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
